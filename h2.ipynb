{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "import random\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "def get_device():\n",
    "   \n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        torch.cuda.set_per_process_memory_fraction(0.8, device=device.index)\n",
    "        print(\"Using GPU with 80% memory usage.\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU.\")\n",
    "    \n",
    "    return device\n",
    "\n",
    "def load_data(data_dir, batch_size, img_size):\n",
    "   \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.RandomAffine(degrees=15, translate=(0.1, 0.1)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5])\n",
    "    ])\n",
    "\n",
    "    dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "    num_classes = len(dataset.classes)\n",
    "\n",
    "    train_size = int(0.7 * len(dataset))\n",
    "    val_size = int(0.15 * len(dataset))\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "    indices = list(range(len(dataset)))\n",
    "    random.shuffle(indices)\n",
    "\n",
    "    train_indices = indices[:train_size]\n",
    "    val_indices = indices[train_size:train_size + val_size]\n",
    "    test_indices = indices[train_size + val_size:]\n",
    "\n",
    "    train_data = torch.utils.data.Subset(dataset, train_indices)\n",
    "    val_data = torch.utils.data.Subset(dataset, val_indices)\n",
    "    test_data = torch.utils.data.Subset(dataset, test_indices)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, num_classes\n",
    "\n",
    "def build_model(num_classes):\n",
    "   \n",
    "    model = models.resnet50(pretrained=True)\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(model.fc.in_features, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(512, num_classes)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_and_evaluate(model, train_loader, val_loader, device, epochs, model_path, optimizer_type='Adam', learning_rate=1e-3, use_tensorboard=True):\n",
    "   \n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    if optimizer_type == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    elif optimizer_type == 'SGD':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported optimizer type. Please choose 'Adam' or 'SGD'.\")\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    if use_tensorboard:\n",
    "        writer = SummaryWriter()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        all_preds, all_labels = [], []\n",
    "        correct = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = 100 * correct / len(train_loader.dataset)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = 100 * val_correct / len(val_loader.dataset)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss  \n",
    "            model_path = \"/kaggle/working/best_model.pth\"\n",
    "            torch.save(model.state_dict(), model_path)  \n",
    "            print(f\"Saved at epoch {epoch+1} with val_loss: {val_loss:.4f}\")\n",
    "\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] | Train Loss: {train_loss:.4f} | Train Accuracy: {train_accuracy:.2f}% | Val Loss: {val_loss:.4f} | Val Accuracy: {val_accuracy:.2f}%\")\n",
    "        \n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        disp = ConfusionMatrixDisplay(cm)\n",
    "        disp.plot(cmap='Blues')\n",
    "        plt.show()\n",
    "        \n",
    "        if use_tensorboard:\n",
    "            writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "            writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "            writer.add_scalar('Accuracy/train', train_accuracy, epoch)\n",
    "            writer.add_scalar('Accuracy/val', val_accuracy, epoch)\n",
    "            writer.add_figure('Confusion Matrix', disp.figure_, epoch)\n",
    "    \n",
    "    if use_tensorboard:\n",
    "        writer.close()\n",
    "\n",
    "\n",
    "def evaluate_on_test_set(model, test_loader, device):\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Loss: {test_loss:.4f} | Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    data_dir = \"../hand_gesture_recognition_project/leapGestRecog\"\n",
    "    batch_size = 60\n",
    "    img_size = 224\n",
    "    epochs = 50\n",
    "    model_path = \"best_model.pth\"\n",
    "    optimizer_type = 'Adam'\n",
    "    learning_rate = 1e-3\n",
    "    use_tensorboard = True\n",
    "    \n",
    "    device = get_device()\n",
    "    train_loader, val_loader, test_loader, num_classes = load_data(data_dir, batch_size, img_size)\n",
    "    model = build_model(num_classes)\n",
    "    train_and_evaluate(model, train_loader, val_loader, device, epochs, model_path, optimizer_type, learning_rate, use_tensorboard)\n",
    "    evaluate_on_test_set(model, test_loader, device)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
