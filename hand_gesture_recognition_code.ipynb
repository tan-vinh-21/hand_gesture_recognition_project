{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Labraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_device():\n",
    "    \"\"\"\n",
    "    Get the device to run the model on (GPU if available with 80% memory usage, else CPU).\n",
    "    \n",
    "    Returns:\n",
    "        device (torch.device): The device to be used.\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        # Set the GPU memory usage limit to 80%\n",
    "        torch.cuda.set_per_process_memory_fraction(0.8, device=device.index)\n",
    "        print(\"Using GPU with 80% memory usage.\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU.\")\n",
    "    \n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir, batch_size, img_size):\n",
    "    \"\"\"\n",
    "    Load and preprocess the dataset.\n",
    "    \n",
    "    Args:\n",
    "        data_dir (str): The directory containing the dataset.\n",
    "        batch_size (int): The batch size for data loading.\n",
    "        img_size (int): The size to resize images to.\n",
    "        \n",
    "    Returns:\n",
    "        train_loader (DataLoader): The DataLoader for the training set.\n",
    "        val_loader (DataLoader): The DataLoader for the validation set.\n",
    "        test_loader (DataLoader): The DataLoader for the test set.\n",
    "        num_classes (int): The number of classes in the dataset.\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5])\n",
    "    ])\n",
    "    dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "    num_classes = len(dataset.classes)\n",
    "    \n",
    "    train_size = int(0.7 * len(dataset))\n",
    "    val_size = int(0.15 * len(dataset))\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "    train_data, val_data, test_data = random_split(dataset, [train_size, val_size, test_size])\n",
    "    \n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_classes):\n",
    "    \"\"\"\n",
    "    Build a ResNet50 model with a custom fully connected layer.\n",
    "    \n",
    "    Args:\n",
    "        num_classes (int): The number of output classes.\n",
    "        \n",
    "    Returns:\n",
    "        model (nn.Module): The ResNet50 model with a modified fully connected layer.\n",
    "    \"\"\"\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(model.fc.in_features, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(512, num_classes)\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_loader, val_loader, device, epochs, model_path, optimizer_type='Adam', learning_rate=1e-3, use_tensorboard=True):\n",
    "    \"\"\"\n",
    "    Train and evaluate the model.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The model to be trained.\n",
    "        train_loader (DataLoader): The DataLoader for the training set.\n",
    "        val_loader (DataLoader): The DataLoader for the validation set.\n",
    "        device (torch.device): The device to run the model on.\n",
    "        epochs (int): The number of epochs to train for.\n",
    "        model_path (str): The path to save the best model.\n",
    "        optimizer_type (str, optional): The type of optimizer to use. Defaults to 'Adam'.\n",
    "        learning_rate (float, optional): The learning rate for the optimizer. Defaults to 1e-3.\n",
    "        use_tensorboard (bool, optional): Whether to use TensorBoard for visualization. Defaults to True.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    if optimizer_type == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    elif optimizer_type == 'SGD':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported optimizer type. Please choose 'Adam' or 'SGD'.\")\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    if use_tensorboard:\n",
    "        writer = SummaryWriter()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        all_preds, all_labels = [], []\n",
    "        correct = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = 100 * correct / len(train_loader.dataset)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = 100 * val_correct / len(val_loader.dataset)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(f\"Model saved at epoch {epoch+1}\")\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] | Train Loss: {train_loss:.4f} | Train Accuracy: {train_accuracy:.2f}% | Val Loss: {val_loss:.4f} | Val Accuracy: {val_accuracy:.2f}%\")\n",
    "        \n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        disp = ConfusionMatrixDisplay(cm)\n",
    "        disp.plot(cmap='Blues')\n",
    "        plt.show()\n",
    "        \n",
    "        if use_tensorboard:\n",
    "            writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "            writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "            writer.add_scalar('Accuracy/train', train_accuracy, epoch)\n",
    "            writer.add_scalar('Accuracy/val', val_accuracy, epoch)\n",
    "            writer.add_figure('Confusion Matrix', disp.figure_, epoch)\n",
    "    \n",
    "    if use_tensorboard:\n",
    "        writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_test_set(model, test_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test set.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The model to be evaluated.\n",
    "        test_loader (DataLoader): The DataLoader for the test set.\n",
    "        device (torch.device): The device to run the model on.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Loss: {test_loss:.4f} | Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m     evaluate_on_test_set(model, test_loader, device)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 18\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[21], line 14\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m train_loader, val_loader, test_loader, num_classes \u001b[38;5;241m=\u001b[39m load_data(data_dir, batch_size, img_size)\n\u001b[0;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m build_model(num_classes)\n\u001b[1;32m---> 14\u001b[0m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_tensorboard\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m evaluate_on_test_set(model, test_loader, device)\n",
      "Cell \u001b[1;32mIn[19], line 42\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(model, train_loader, val_loader, device, epochs, model_path, optimizer_type, learning_rate, use_tensorboard)\u001b[0m\n\u001b[0;32m     40\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[0;32m     41\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m---> 42\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     44\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    625\u001b[0m     )\n\u001b[1;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    824\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    825\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    data_dir = \"../hand_gesture_recognition_project/leapGestRecog\"\n",
    "    batch_size = 60\n",
    "    img_size = 224\n",
    "    epochs = 50\n",
    "    model_path = \"best_model.pth\"\n",
    "    optimizer_type = 'Adam'\n",
    "    learning_rate = 1e-3\n",
    "    use_tensorboard = True\n",
    "    \n",
    "    device = get_device()\n",
    "    train_loader, val_loader, test_loader, num_classes = load_data(data_dir, batch_size, img_size)\n",
    "    model = build_model(num_classes)\n",
    "    train_and_evaluate(model, train_loader, val_loader, device, epochs, model_path, optimizer_type, learning_rate, use_tensorboard)\n",
    "    evaluate_on_test_set(model, test_loader, device)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
