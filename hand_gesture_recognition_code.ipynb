{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Labraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "import random\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_device():\n",
    "    \"\"\"\n",
    "    Get the device to run the model on (GPU if available with 80% memory usage, else CPU).\n",
    "    \n",
    "    Returns:\n",
    "        device (torch.device): The device to be used.\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        # Set the GPU memory usage limit to 80%\n",
    "        torch.cuda.set_per_process_memory_fraction(0.8, device=device.index)\n",
    "        print(\"Using GPU with 80% memory usage.\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU.\")\n",
    "    \n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir, batch_size, img_size):\n",
    "    \"\"\"\n",
    "    Load and preprocess the dataset while ensuring that training, validation,\n",
    "    and test sets contain images from all users to prevent user bias.\n",
    "    \n",
    "    Args:\n",
    "        data_dir (str): The directory containing the dataset.\n",
    "        batch_size (int): The batch size for data loading.\n",
    "        img_size (int): The size to resize images to.\n",
    "        \n",
    "    Returns:\n",
    "        train_loader (DataLoader): The DataLoader for the training set.\n",
    "        val_loader (DataLoader): The DataLoader for the validation set.\n",
    "        test_loader (DataLoader): The DataLoader for the test set.\n",
    "        num_classes (int): The number of classes in the dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    # ✅ 1. Augmentation để giảm overfitting theo người\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.RandomAffine(degrees=15, translate=(0.1, 0.1)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5])\n",
    "    ])\n",
    "\n",
    "    # ✅ 2. Load toàn bộ dataset\n",
    "    dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "    num_classes = len(dataset.classes)\n",
    "\n",
    "    # ✅ 3. Chia dữ liệu theo động tác, đảm bảo train/test đều có ảnh của tất cả 10 người\n",
    "    train_size = int(0.7 * len(dataset))\n",
    "    val_size = int(0.15 * len(dataset))\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "    # ✅ 4. Shuffle ngẫu nhiên để đảm bảo dữ liệu không bị chia theo người\n",
    "    indices = list(range(len(dataset)))\n",
    "    random.shuffle(indices)\n",
    "\n",
    "    train_indices = indices[:train_size]\n",
    "    val_indices = indices[train_size:train_size + val_size]\n",
    "    test_indices = indices[train_size + val_size:]\n",
    "\n",
    "    train_data = torch.utils.data.Subset(dataset, train_indices)\n",
    "    val_data = torch.utils.data.Subset(dataset, val_indices)\n",
    "    test_data = torch.utils.data.Subset(dataset, test_indices)\n",
    "\n",
    "    # ✅ 5. Load data với shuffle để tránh bias\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_classes):\n",
    "    \"\"\"\n",
    "    Build a ResNet50 model with a custom fully connected layer.\n",
    "    \n",
    "    Args:\n",
    "        num_classes (int): The number of output classes.\n",
    "        \n",
    "    Returns:\n",
    "        model (nn.Module): The ResNet50 model with a modified fully connected layer.\n",
    "    \"\"\"\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(model.fc.in_features, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(512, num_classes)\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_loader, val_loader, device, epochs, model_path, optimizer_type='Adam', learning_rate=1e-3, use_tensorboard=True):\n",
    "    \"\"\"\n",
    "    Train and evaluate the model.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The model to be trained.\n",
    "        train_loader (DataLoader): The DataLoader for the training set.\n",
    "        val_loader (DataLoader): The DataLoader for the validation set.\n",
    "        device (torch.device): The device to run the model on.\n",
    "        epochs (int): The number of epochs to train for.\n",
    "        model_path (str): The path to save the best model.\n",
    "        optimizer_type (str, optional): The type of optimizer to use. Defaults to 'Adam'.\n",
    "        learning_rate (float, optional): The learning rate for the optimizer. Defaults to 1e-3.\n",
    "        use_tensorboard (bool, optional): Whether to use TensorBoard for visualization. Defaults to True.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    if optimizer_type == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    elif optimizer_type == 'SGD':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported optimizer type. Please choose 'Adam' or 'SGD'.\")\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    if use_tensorboard:\n",
    "        writer = SummaryWriter()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        all_preds, all_labels = [], []\n",
    "        correct = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = 100 * correct / len(train_loader.dataset)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = 100 * val_correct / len(val_loader.dataset)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss  # Cập nhật giá trị tốt nhất\n",
    "            model_path = \"/kaggle/working/best_model.pth\"\n",
    "            torch.save(model.state_dict(), model_path)  # Lưu mô hình\n",
    "            print(f\"Saved at epoch {epoch+1} with val_loss: {val_loss:.4f}\")\n",
    "\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] | Train Loss: {train_loss:.4f} | Train Accuracy: {train_accuracy:.2f}% | Val Loss: {val_loss:.4f} | Val Accuracy: {val_accuracy:.2f}%\")\n",
    "        \n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        disp = ConfusionMatrixDisplay(cm)\n",
    "        disp.plot(cmap='Blues')\n",
    "        plt.show()\n",
    "        \n",
    "        if use_tensorboard:\n",
    "            writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "            writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "            writer.add_scalar('Accuracy/train', train_accuracy, epoch)\n",
    "            writer.add_scalar('Accuracy/val', val_accuracy, epoch)\n",
    "            writer.add_figure('Confusion Matrix', disp.figure_, epoch)\n",
    "    \n",
    "    if use_tensorboard:\n",
    "        writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_test_set(model, test_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test set.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The model to be evaluated.\n",
    "        test_loader (DataLoader): The DataLoader for the test set.\n",
    "        device (torch.device): The device to run the model on.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Loss: {test_loss:.4f} | Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    data_dir = \"../hand_gesture_recognition_project/leapGestRecog\"\n",
    "    batch_size = 60\n",
    "    img_size = 224\n",
    "    epochs = 50\n",
    "    model_path = \"best_model.pth\"\n",
    "    optimizer_type = 'Adam'\n",
    "    learning_rate = 1e-3\n",
    "    use_tensorboard = True\n",
    "    \n",
    "    device = get_device()\n",
    "    train_loader, val_loader, test_loader, num_classes = load_data(data_dir, batch_size, img_size)\n",
    "    model = build_model(num_classes)\n",
    "    train_and_evaluate(model, train_loader, val_loader, device, epochs, model_path, optimizer_type, learning_rate, use_tensorboard)\n",
    "    evaluate_on_test_set(model, test_loader, device)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
